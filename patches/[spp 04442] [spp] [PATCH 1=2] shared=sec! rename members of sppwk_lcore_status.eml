Return-path: <fw-yama-hd@pomail01.silk.ntt-tx.co.jp>
Received: from zssg-mailmd104.ddreams.local
 (zssg-mailmd104.ddreams.local [10.160.123.99]) by zssg-mailms320.ddreams.local
 (NTT DoCoMo Mail System) with ESMTP id <0PTO00QYBY9FV480@NTTDoCoMo.co.jp> for
 yamashita.hideyuki@ntt-tx.co.jp; Wed, 26 Jun 2019 14:36:51 +0900 (JST)
Original-recipient: rfc822;yamashita.hideyuki@ntt-tx.co.jp
Received: from smtp_saver-daemon.zssg-mailmd104.ddreams.local by
 zssg-mailmd104.ddreams.local (dDREAMS) id <0PTO00Z3GY9FLO00@dDREAMS> for
 yamashita.hideyuki@ntt-tx.co.jp (ORCPT yamashita.hideyuki@ntt-tx.co.jp); Wed,
 26 Jun 2019 14:36:51 +0900 (JST)
Received: from zssg-mailmf102.ddreams.local
 (zssg-mailmf900.ddreams.local [10.160.172.84]) by zssg-mailmd104.ddreams.local
 (dDREAMS) with ESMTP id <0PTO00W3QY9F6T20@dDREAMS> for
 yamashita.hideyuki@ntt-tx.co.jp (ORCPT yamashita.hideyuki@ntt-tx.co.jp); Wed,
 26 Jun 2019 14:36:51 +0900 (JST)
Received: from zssg-mailmf102.ddreams.local (unknown [127.0.0.1])
	by zssg-mailmf102.ddreams.local (Postfix) with ESMTP id 55CCC7E6032	for
 <yamashita.hideyuki@ntt-tx.co.jp>; Wed, 26 Jun 2019 14:36:51 +0900 (JST)
Received: from zssg-mailmf102.ddreams.local (unknown [127.0.0.1])
	by IMSVA (Postfix) with ESMTP id 54C648E6058	for
 <yamashita.hideyuki@ntt-tx.co.jp>; Wed, 26 Jun 2019 14:36:51 +0900 (JST)
Received: from localhost (unknown [127.0.0.1])	by IMSVA (Postfix)
 with SMTP id 4A0348E6056	for <yamashita.hideyuki@ntt-tx.co.jp>; Wed,
 26 Jun 2019 14:36:51 +0900 (JST)
X-IMSS-HAND-OFF-DIRECTIVE: localhost:10026
Received: from zssg-mailmf102.ddreams.local (unknown [127.0.0.1])
	by IMSVA (Postfix) with ESMTP id 12BA98E6050	for
 <yamashita.hideyuki@ntt-tx.co.jp>; Wed, 26 Jun 2019 14:36:50 +0900 (JST)
Received: from pomail01.silk.ntt-tx.co.jp (unknown [10.160.183.139])
	by zssg-mailmf102.ddreams.local (Postfix)
 with ESMTPS	for <yamashita.hideyuki@ntt-tx.co.jp>; Wed,
 26 Jun 2019 14:36:50 +0900 (JST)
Received: from pomail01.silk.ntt-tx.co.jp (localhost [127.0.0.1])
	by pomail01.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5anb3019251;	Wed,
 26 Jun 2019 14:36:49 +0900
Received: (from yama-hd@localhost)	by pomail01.silk.ntt-tx.co.jp (unknown)
 id x5Q5anqV019250;	Wed, 26 Jun 2019 14:36:49 +0900
X-Authentication-warning: pomail01.silk.ntt-tx.co.jp: yama-hd set sender to
 fw-yama-hd@pomail01.silk.ntt-tx.co.jp using -f
Received: from imss04.silk.ntt-tx.co.jp
 (imss04.silk.ntt-tx.co.jp [10.107.0.39])	by pomail01.silk.ntt-tx.co.jp
 (unknown) with ESMTP id x5Q5an1e019247	for unknown; Wed,
 26 Jun 2019 14:36:49 +0900
Received: from imss04.silk.ntt-tx.co.jp (localhost [127.0.0.1])
 by imss04.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5anUG032103 for
 unknown; Wed, 26 Jun 2019 14:36:49 +0900
Received: from ml01.silk.ntt-tx.co.jp (ml01.silk.ntt-tx.co.jp [10.107.0.230])
 by imss04.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5anAJ032099; Wed,
 26 Jun 2019 14:36:49 +0900
Received: from ml01.silk.ntt-tx.co.jp (localhost [127.0.0.1])
	by ml01.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5anZ1015890;	Wed,
 26 Jun 2019 14:36:49 +0900
Received: from imss01.silk.ntt-tx.co.jp
 (imss01.silk.ntt-tx.co.jp [10.107.0.126])	by ml01.silk.ntt-tx.co.jp (unknown)
 with ESMTP id x5Q5anIW015886	for unknown; Wed, 26 Jun 2019 14:36:49 +0900
Received: from imss01.silk.ntt-tx.co.jp (localhost [127.0.0.1])
 by imss01.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5am4P011116 for
 unknown; Wed, 26 Jun 2019 14:36:48 +0900
Received: from mail01.ics.ntt-tx.co.jp (mail01.ics.ntt-tx.co.jp [10.254.2.67])
 by imss01.silk.ntt-tx.co.jp (unknown) with ESMTP id x5Q5amDH011112 for
 unknown; Wed, 26 Jun 2019 14:36:48 +0900
Received: from dpdk.org (dpdk.org [92.243.14.124])	by mail01.ics.ntt-tx.co.jp
 (unknown) with SMTP id x5Q5agJl026488	for unknown; Wed,
 26 Jun 2019 14:36:48 +0900
Received: from [92.243.14.124] (localhost [127.0.0.1])	by dpdk.org (Postfix)
 with ESMTP id D6FF11B954;	Wed, 26 Jun 2019 07:36:41 +0200 (CEST)
Received: from mail-pf1-f193.google.com
 (mail-pf1-f193.google.com [209.85.210.193]) by dpdk.org (Postfix)
 with ESMTP id 2A7411B951 for <spp@dpdk.org>; Wed,
 26 Jun 2019 07:36:40 +0200 (CEST)
Received: by mail-pf1-f193.google.com with SMTP id y15so704648pfn.5 for
 <spp@dpdk.org>; Tue, 25 Jun 2019 22:36:40 -0700 (PDT)
Received: from localhost.localdomain ([192.47.164.146])
 by smtp.gmail.com with ESMTPSA id t29sm25684292pfq.156.2019.06.25.22.36.37
 (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128); Tue,
 25 Jun 2019 22:36:38 -0700 (PDT)
Date: Wed, 26 Jun 2019 14:36:32 +0900
From: yasufum.o@gmail.com
Subject: [spp 04442] [spp] [PATCH 1/2] shared/sec: rename members of
 sppwk_lcore_status
Sender: spp <spp-bounces@dpdk.org>
To: spp@dpdk.org, ferruh.yigit@intel.com, yasufum.o@gmail.com
Message-id: <20190626053633.39963-2-yasufum.o@gmail.com>
In-reply-to: <20190626053633.39963-1-yasufum.o@gmail.com>
References: <20190626053633.39963-1-yasufum.o@gmail.com>
X-ML-Name: unknown
X-Mail-Count: 04442
X-MLServer: unknown
X-ML-Info: mailing list service
X-Mailer: git-send-email 2.17.1
Authentication-results: mail01.ics.ntt-tx.co.jp; spf=pass
 smtp.mailfrom=spp-bounces@dpdk.org
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=gmail.com; s=20161025;
 h=from:to:subject:date:message-id:in-reply-to:references;
 bh=aSgb+y4qa5qDmnzLDVFegv67WxZpAFrT7acGM0xquF4=;
 b=F8/KWN+TiYkaVMN66sn/kGdE2qlDcWD+Lk/0RhNIkVq/9qFnzchc3Kk6tHgRMEKGlE
 vnfThDynljPBwkW+AVBwj8aStPUH3BxqhU7DI7UF5GLbM6BGgYcZBza7SmmHWYxoiMKp
 WdeVfFM/XGeLDX1o3cj08gnEzr7izqsu19iUyK8Q9OO4SAnCpSlsOfgS6YHs1lwe2zVM
 sr54OsxEsK4BUZnLw/xjdDvSFNFm0dNnM6mKZgWIVdwT2Qb+y0ANBjlBrRa+0Yp07sF9
 oP4Cq3GUHO4crg1WkUOrizS2tOa10tpZ5SGP5UtKO42CumX9tl8m5FIBq/INYhguiCVK BvGQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=1e100.net;
 s=20161025; h=x-gm-message-state:from:to:subject:date:message-id:in-reply-to
 :references; bh=aSgb+y4qa5qDmnzLDVFegv67WxZpAFrT7acGM0xquF4=;
 b=s/hHnJvTtj9wSRkJiiW0p66Dh1jN82eCXBbuMTaMZ7FBv67op2QIZr94nRPkKaQf4b
 1HqRjIVabxxnhfv+vdmvTPEvnGKAZD+9ppoEKsSBB/UPgmWkTWqfbomtPyJpMVZDCXgP
 /FoaHc8PswUrqktOy6w9uOJZP4c8e2124jgz8KuNET+jhbzwE/guf3BwEKW1BlsRr3zF
 dO6SlCkvjiVrg7SLrXwsGO7i7ixEUrI1F9uzS6RHzxDJQV+QfJyqnluxo09yEupNanhQ
 q1a4vukanq0EBBiNKLYYhmex2lDWV1JHvBnszeIHXBLGNrRCMUjHBZi0/4kemGMn9sPF M9Sg==
X-Gm-Message-State: APjAAAXYKroSDnKLx90N7NgXJUdv5sWpQ2k7UlYckfBhYdOdz60s7jHe
 44quP012RJiRQygHPGHu/5v0B182
X-Google-Smtp-Source:
 APXvYqyNomVDxhO6WfCRaZpSKT+tUc9KGc5NJbaOZxsgo/AQlCEoWIIvxzcFcz2Zy84nXAink8cAiA==
X-Received: by 2002:a65:480b:: with SMTP id h11mr1107881pgs.222.1561527399137;
 Tue, 25 Jun 2019 22:36:39 -0700 (PDT)
X-BeenThere: spp@dpdk.org
X-Mailman-Version: 2.1.15
List-Id: Soft Patch Panel <spp.dpdk.org>
List-Unsubscribe: <https://mails.dpdk.org/options/spp>,
 <mailto:spp-request@dpdk.org?subject=unsubscribe>
List-Archive: <http://mails.dpdk.org/archives/spp/>
List-Post: <mailto:spp@dpdk.org>
List-Help: <mailto:spp-request@dpdk.org?subject=help>
List-Subscribe: <https://mails.dpdk.org/listinfo/spp>,
 <mailto:spp-request@dpdk.org?subject=subscribe>
X-TM-AS-MML: No
Precedence: bulk
Lines: 300
X-TM-AS-GCONF: 00
X-MD-STAMP: ON

From: Yasufumi Ogawa <yasufum.o@gmail.com>

This update is to rename members of enum `sppwk_lcore_status` which
defines each of status of worker threads, such as idling or running or
so.

Signed-off-by: Yasufumi Ogawa <yasufum.o@gmail.com>
---
 src/mirror/mir_cmd_runner.c                   |  9 +++----
 src/mirror/spp_mirror.c                       | 24 +++++++++----------
 .../secondary/spp_worker_th/cmd_utils.c       |  8 +++----
 .../secondary/spp_worker_th/cmd_utils.h       | 15 ++++++------
 src/vf/spp_vf.c                               | 24 +++++++++----------
 src/vf/vf_cmd_runner.c                        |  9 +++----
 6 files changed, 45 insertions(+), 44 deletions(-)

diff --git a/src/mirror/mir_cmd_runner.c b/src/mirror/mir_cmd_runner.c
index f63a84b..17c2c27 100644
--- a/src/mirror/mir_cmd_runner.c
+++ b/src/mirror/mir_cmd_runner.c
@@ -39,9 +39,10 @@ update_comp(enum sppwk_action wk_action, const char *name,
 	switch (wk_action) {
 	case SPPWK_ACT_START:
 		info = (core_info + lcore_id);
-		if (info->status == SPP_CORE_UNUSE) {
-			RTE_LOG(ERR, MIR_CMD_RUNNER, "Core %d is not available because "
-				"it is in SPP_CORE_UNUSE state.\n", lcore_id);
+		if (info->status == SPPWK_LCORE_UNUSED) {
+			RTE_LOG(ERR, MIR_CMD_RUNNER,
+					"Not available lcore %d for %s.\n",
+					lcore_id, "SPPWK_LCORE_UNUSED");
 			return SPP_RET_NG;
 		}
 
@@ -302,7 +303,7 @@ spp_iterate_core_info(struct spp_iterate_core_params *params)
 	struct sppwk_comp_info *comp_info = NULL;
 
 	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (spp_get_core_status(lcore_id) == SPP_CORE_UNUSE)
+		if (spp_get_core_status(lcore_id) == SPPWK_LCORE_UNUSED)
 			continue;
 
 		core = get_core_info(lcore_id);
diff --git a/src/mirror/spp_mirror.c b/src/mirror/spp_mirror.c
index 898755d..695f3ac 100644
--- a/src/mirror/spp_mirror.c
+++ b/src/mirror/spp_mirror.c
@@ -414,16 +414,16 @@ slave_main(void *arg __attribute__ ((unused)))
 	int ret = SPP_RET_OK;
 	int cnt = 0;
 	unsigned int lcore_id = rte_lcore_id();
-	enum sppwk_lcore_status status = SPP_CORE_STOP;
+	enum sppwk_lcore_status status = SPPWK_LCORE_STOPPED;
 	struct core_mng_info *info = &g_core_info[lcore_id];
 	struct core_info *core = get_core_info(lcore_id);
 
 	RTE_LOG(INFO, MIRROR, "Slave started on lcore %d.\n", lcore_id);
-	set_core_status(lcore_id, SPP_CORE_IDLE);
+	set_core_status(lcore_id, SPPWK_LCORE_IDLING);
 
 	while ((status = spp_get_core_status(lcore_id)) !=
-			SPP_CORE_STOP_REQUEST) {
-		if (status != SPP_CORE_FORWARD)
+			SPPWK_LCORE_REQ_STOP) {
+		if (status != SPPWK_LCORE_RUNNING)
 			continue;
 
 		if (spp_check_core_update(lcore_id) == SPP_RET_OK) {
@@ -449,7 +449,7 @@ slave_main(void *arg __attribute__ ((unused)))
 		}
 	}
 
-	set_core_status(lcore_id, SPP_CORE_STOP);
+	set_core_status(lcore_id, SPPWK_LCORE_STOPPED);
 	RTE_LOG(INFO, MIRROR, "Terminated slave on lcore %d.\n", lcore_id);
 	return ret;
 }
@@ -544,13 +544,13 @@ main(int argc, char *argv[])
 		}
 
 		/* Set the status of main thread to idle */
-		g_core_info[master_lcore].status = SPP_CORE_IDLE;
-		int ret_wait = check_core_status_wait(SPP_CORE_IDLE);
+		g_core_info[master_lcore].status = SPPWK_LCORE_IDLING;
+		int ret_wait = check_core_status_wait(SPPWK_LCORE_IDLING);
 		if (unlikely(ret_wait != 0))
 			break;
 
 		/* Start forwarding */
-		set_all_core_status(SPP_CORE_FORWARD);
+		set_all_core_status(SPPWK_LCORE_RUNNING);
 #ifdef SPP_MIRROR_SHALLOWCOPY
 		RTE_LOG(INFO, MIRROR,
 			"My ID %d start handling messagei(ShallowCopy)\n", 0);
@@ -567,7 +567,7 @@ main(int argc, char *argv[])
 		int ret_do = 0;
 #ifndef USE_UT_SPP_VF
 		while (likely(g_core_info[master_lcore].status !=
-				SPP_CORE_STOP_REQUEST)) {
+				SPPWK_LCORE_REQ_STOP)) {
 #else
 		{
 #endif
@@ -587,7 +587,7 @@ main(int argc, char *argv[])
 		}
 
 		if (unlikely(ret_do != SPP_RET_OK)) {
-			set_all_core_status(SPP_CORE_STOP_REQUEST);
+			set_all_core_status(SPPWK_LCORE_REQ_STOP);
 			break;
 		}
 
@@ -596,8 +596,8 @@ main(int argc, char *argv[])
 	}
 
 	/* Finalize to exit */
-	g_core_info[master_lcore].status = SPP_CORE_STOP;
-	int ret_core_end = check_core_status_wait(SPP_CORE_STOP);
+	g_core_info[master_lcore].status = SPPWK_LCORE_STOPPED;
+	int ret_core_end = check_core_status_wait(SPPWK_LCORE_STOPPED);
 	if (unlikely(ret_core_end != 0))
 		RTE_LOG(ERR, MIRROR, "Failed to terminate master thread.\n");
 
diff --git a/src/shared/secondary/spp_worker_th/cmd_utils.c b/src/shared/secondary/spp_worker_th/cmd_utils.c
index 32929ec..6f93400 100644
--- a/src/shared/secondary/spp_worker_th/cmd_utils.c
+++ b/src/shared/secondary/spp_worker_th/cmd_utils.c
@@ -130,7 +130,7 @@ set_all_core_status(enum sppwk_lcore_status status)
 }
 
 /**
- * Set all of component status to SPP_CORE_STOP_REQUEST if received signal
+ * Set all of component status to SPPWK_LCORE_REQ_STOP if received signal
  * is SIGTERM or SIGINT
  */
 void
@@ -144,8 +144,8 @@ stop_process(int signal)
 
 	master_lcore = rte_get_master_lcore();
 	(g_mng_data.p_core_info + master_lcore)->status =
-		SPP_CORE_STOP_REQUEST;
-	set_all_core_status(SPP_CORE_STOP_REQUEST);
+		SPPWK_LCORE_REQ_STOP;
+	set_all_core_status(SPPWK_LCORE_REQ_STOP);
 }
 
 /**
@@ -397,7 +397,7 @@ init_core_info(void)
 	struct core_mng_info *p_core_info = g_mng_data.p_core_info;
 	memset(p_core_info, 0x00,
 			sizeof(struct core_mng_info)*RTE_MAX_LCORE);
-	set_all_core_status(SPP_CORE_STOP);
+	set_all_core_status(SPPWK_LCORE_STOPPED);
 	for (cnt = 0; cnt < RTE_MAX_LCORE; cnt++) {
 		(p_core_info + cnt)->ref_index = 0;
 		(p_core_info + cnt)->upd_index = 1;
diff --git a/src/shared/secondary/spp_worker_th/cmd_utils.h b/src/shared/secondary/spp_worker_th/cmd_utils.h
index f33bc62..596ba5e 100644
--- a/src/shared/secondary/spp_worker_th/cmd_utils.h
+++ b/src/shared/secondary/spp_worker_th/cmd_utils.h
@@ -74,14 +74,13 @@
 #define CORE_TYPE_FORWARD_STR	     "forward"
 #define CORE_TYPE_MIRROR_STR	     "mirror"
 
-/* State on component */
+/* Status of a component on lcore. */
 enum sppwk_lcore_status {
-	SPP_CORE_UNUSE,        /**< Not used */
-	SPP_CORE_STOP,         /**< Stopped */
-	SPP_CORE_IDLE,         /**< Idling */
-	SPP_CORE_FORWARD,      /**< Forwarding  */
-	SPP_CORE_STOP_REQUEST, /**< Request stopping */
-	SPP_CORE_IDLE_REQUEST /**< Request idling */
+	SPPWK_LCORE_UNUSED,
+	SPPWK_LCORE_STOPPED,
+	SPPWK_LCORE_IDLING,
+	SPPWK_LCORE_RUNNING,
+	SPPWK_LCORE_REQ_STOP  /**< Request stopping */
 };
 
 /* Type of SPP worker thread. */
@@ -336,7 +335,7 @@ void set_core_status(unsigned int lcore_id, enum sppwk_lcore_status status);
 void set_all_core_status(enum sppwk_lcore_status status);
 
 /**
- * Set all comp status to SPP_CORE_STOP_REQUEST if received SIGTERM or SIGINT.
+ * Set all comp status to SPPWK_LCORE_REQ_STOP if received SIGTERM or SIGINT.
  *
  * @param[in] signal Received signal.
  */
diff --git a/src/vf/spp_vf.c b/src/vf/spp_vf.c
index 0068329..18a3619 100644
--- a/src/vf/spp_vf.c
+++ b/src/vf/spp_vf.c
@@ -140,16 +140,16 @@ slave_main(void *arg __attribute__ ((unused)))
 	int ret = 0;
 	int cnt = 0;
 	unsigned int lcore_id = rte_lcore_id();
-	enum sppwk_lcore_status status = SPP_CORE_STOP;
+	enum sppwk_lcore_status status = SPPWK_LCORE_STOPPED;
 	struct core_mng_info *info = &g_core_info[lcore_id];
 	struct core_info *core = get_core_info(lcore_id);
 
 	RTE_LOG(INFO, APP, "Slave started on lcore %d.\n", lcore_id);
-	set_core_status(lcore_id, SPP_CORE_IDLE);
+	set_core_status(lcore_id, SPPWK_LCORE_IDLING);
 
 	while ((status = spp_get_core_status(lcore_id)) !=
-			SPP_CORE_STOP_REQUEST) {
-		if (status != SPP_CORE_FORWARD)
+			SPPWK_LCORE_REQ_STOP) {
+		if (status != SPPWK_LCORE_RUNNING)
 			continue;
 
 		if (spp_check_core_update(lcore_id) == SPP_RET_OK) {
@@ -182,7 +182,7 @@ slave_main(void *arg __attribute__ ((unused)))
 		}
 	}
 
-	set_core_status(lcore_id, SPP_CORE_STOP);
+	set_core_status(lcore_id, SPPWK_LCORE_STOPPED);
 	RTE_LOG(INFO, APP, "Terminated slave on lcore %d.\n", lcore_id);
 	return ret;
 }
@@ -271,13 +271,13 @@ main(int argc, char *argv[])
 
 		/* Set the status of main thread to idle */
 		master_lcore = rte_get_master_lcore();
-		g_core_info[master_lcore].status = SPP_CORE_IDLE;
-		int ret_wait = check_core_status_wait(SPP_CORE_IDLE);
+		g_core_info[master_lcore].status = SPPWK_LCORE_IDLING;
+		int ret_wait = check_core_status_wait(SPPWK_LCORE_IDLING);
 		if (unlikely(ret_wait != SPP_RET_OK))
 			break;
 
 		/* Start forwarding */
-		set_all_core_status(SPP_CORE_FORWARD);
+		set_all_core_status(SPPWK_LCORE_RUNNING);
 		RTE_LOG(INFO, APP, "My ID %d start handling message\n", 0);
 		RTE_LOG(INFO, APP, "[Press Ctrl-C to quit ...]\n");
 
@@ -288,7 +288,7 @@ main(int argc, char *argv[])
 		int ret_do = SPP_RET_OK;
 #ifndef USE_UT_SPP_VF
 		while (likely(g_core_info[master_lcore].status !=
-				SPP_CORE_STOP_REQUEST)) {
+				SPPWK_LCORE_REQ_STOP)) {
 #else
 		{
 #endif
@@ -308,7 +308,7 @@ main(int argc, char *argv[])
 		}
 
 		if (unlikely(ret_do != SPP_RET_OK)) {
-			set_all_core_status(SPP_CORE_STOP_REQUEST);
+			set_all_core_status(SPPWK_LCORE_REQ_STOP);
 			break;
 		}
 
@@ -317,8 +317,8 @@ main(int argc, char *argv[])
 	}
 
 	/* Finalize to exit */
-	g_core_info[master_lcore].status = SPP_CORE_STOP;
-	int ret_core_end = check_core_status_wait(SPP_CORE_STOP);
+	g_core_info[master_lcore].status = SPPWK_LCORE_STOPPED;
+	int ret_core_end = check_core_status_wait(SPPWK_LCORE_STOPPED);
 	if (unlikely(ret_core_end != SPP_RET_OK))
 		RTE_LOG(ERR, APP, "Failed to terminate master thread.\n");
 
diff --git a/src/vf/vf_cmd_runner.c b/src/vf/vf_cmd_runner.c
index d9adc48..f5854b0 100644
--- a/src/vf/vf_cmd_runner.c
+++ b/src/vf/vf_cmd_runner.c
@@ -137,9 +137,10 @@ update_comp(enum sppwk_action wk_action, const char *name,
 	switch (wk_action) {
 	case SPPWK_ACT_START:
 		info = (core_info + lcore_id);
-		if (info->status == SPP_CORE_UNUSE) {
-			RTE_LOG(ERR, VF_CMD_RUNNER, "Core %d is not available because "
-				"it is in SPP_CORE_UNUSE state.\n", lcore_id);
+		if (info->status == SPPWK_LCORE_UNUSED) {
+			RTE_LOG(ERR, VF_CMD_RUNNER,
+					"Not available lcore %d for %s.\n",
+					lcore_id, "SPPWK_LCORE_UNUSED");
 			return SPP_RET_NG;
 		}
 
@@ -436,7 +437,7 @@ spp_iterate_core_info(struct spp_iterate_core_params *params)
 	struct sppwk_comp_info *comp_info = NULL;
 
 	RTE_LCORE_FOREACH_SLAVE(lcore_id) {
-		if (spp_get_core_status(lcore_id) == SPP_CORE_UNUSE)
+		if (spp_get_core_status(lcore_id) == SPPWK_LCORE_UNUSED)
 			continue;
 
 		core = get_core_info(lcore_id);
-- 
2.17.1


